{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import dump, load\n",
    "\n",
    "\n",
    "\n",
    "def load_data(data_path, data_path_time):\n",
    "    time_start=time.time()\n",
    "    \n",
    "    #Load data\n",
    "    data_list = []\n",
    "    for fname in sorted(os.listdir(data_path)):\n",
    "        subject_data_path = os.path.join(data_path, fname)\n",
    "        print(subject_data_path)\n",
    "        if not os.path.isfile(subject_data_path): continue\n",
    "        data_list.append(\n",
    "            pd.read_csv(\n",
    "                        subject_data_path,\n",
    "                        sep='|', \n",
    "                        header=None,\n",
    "                        names = [\n",
    "                                'CREDIT_SCORE',\n",
    "                                'FIRST_PAYMENT_DATE',\n",
    "                                'FIRST_TIME_HOMEBUYER_FLAG',\n",
    "                                '4','5','6',\n",
    "                                'NUMBER_OF_UNITS',\n",
    "                                'OCCUPANCY_STATUS',\n",
    "                                '9',\n",
    "                                'ORIGINAL_DTI_RATIO',\n",
    "                                'ORIGINAL_UPB',\n",
    "                                'ORIGINAL_LTV',\n",
    "                                'ORIGINAL_INTEREST_RATE',\n",
    "                                'CHANNEL',\n",
    "                                '15',\n",
    "                                'PRODUCT_TYPE',\n",
    "                                'PROPERTY_STATE',\n",
    "                                'PROPERTY_TYPE',\n",
    "                                '19',\n",
    "                                'LOAN_SQ_NUMBER',\n",
    "                                'LOAN_PURPOSE',\n",
    "                                'ORIGINAL_LOAN_TERM',\n",
    "                                'NUMBER_OF_BORROWERS',\n",
    "                                '24','25','26'#,'27'#data from every year may have different column number\n",
    "                        ],\n",
    "                        usecols=[\n",
    "                            'CREDIT_SCORE',\n",
    "                            'FIRST_TIME_HOMEBUYER_FLAG',\n",
    "                            'NUMBER_OF_UNITS',\n",
    "                            'OCCUPANCY_STATUS',\n",
    "                            'ORIGINAL_DTI_RATIO',\n",
    "                            'ORIGINAL_UPB',\n",
    "                            'ORIGINAL_LTV',\n",
    "                            'ORIGINAL_INTEREST_RATE',\n",
    "                            'CHANNEL',\n",
    "                            'PROPERTY_TYPE',\n",
    "                            'LOAN_SQ_NUMBER',\n",
    "                            'LOAN_PURPOSE',\n",
    "                            'ORIGINAL_LOAN_TERM',\n",
    "                            'NUMBER_OF_BORROWERS'\n",
    "                        ],\n",
    "                        dtype={'CREDIT_SCORE':np.float_, \n",
    "                               'FIRST_TIME_HOMEBUYER_FLAG':np.str, \n",
    "                               'NUMBER_OF_UNITS':np.int_, \n",
    "                               'OCCUPANCY_STATUS':np.str,\n",
    "                               'ORIGINAL_DTI_RATIO':np.float_,\n",
    "                               'ORIGINAL_UPB':np.float_,\n",
    "                               'ORIGINAL_LTV':np.float_,\n",
    "                               'ORIGINAL_INTEREST_RATE':np.float_,\n",
    "                               'CHANNEL':np.str,\n",
    "                               'PROPERTY_TYPE':np.str,\n",
    "                               'LOAN_SQ_NUMBER':np.str,\n",
    "                               'LOAN_PURPOSE':np.str,\n",
    "                               'ORIGINAL_LOAN_TERM':np.int_,\n",
    "                               'NUMBER_OF_BORROWERS':np.int_},\n",
    "                        low_memory=False\n",
    "                        )\n",
    "        )\n",
    "    data = pd.concat(data_list)\n",
    "    \n",
    "    #Load data with time\n",
    "    data_p_list=[]\n",
    "    for fname in sorted(os.listdir(data_path_time)):\n",
    "        subject_data_path = os.path.join(data_path_time, fname)\n",
    "        print(subject_data_path)\n",
    "        if not os.path.isfile(subject_data_path): continue\n",
    "        data_p_list.append(\n",
    "            pd.read_csv(subject_data_path,\n",
    "                             sep='|',\n",
    "                             header=None,\n",
    "                             usecols=[0,3,4],\n",
    "                             dtype={'0':np.str, '3':np.str, '4':np.int_}\n",
    "                            )\n",
    "        )\n",
    "    #data_p = pd.concat(data_p_list)\n",
    "    \n",
    "    #Calculate default\n",
    "    default_list=[]\n",
    "    for data_p in data_p_list:\n",
    "        data_p[3] = data_p[3].astype(str)\n",
    "        clean_index = data_p.iloc[:,1].str.isdigit()\n",
    "        data_p_cleaned = data_p[clean_index].copy()\n",
    "        data_p_cleaned[3] = data_p_cleaned[3].astype(int)\n",
    "        data_less_than_48 = data_p_cleaned[data_p_cleaned[4] < 48]\n",
    "        default_list.append(data_less_than_48[data_less_than_48[3] > 2])\n",
    "    \n",
    "    data_default = pd.concat(default_list)\n",
    "    \n",
    "    default_index = data['LOAN_SQ_NUMBER'].isin(data_default[0].tolist())\n",
    "    \n",
    "    \n",
    "    \n",
    "    data['default_flag']=default_index\n",
    "    \n",
    "    \n",
    "    data.drop(columns=['LOAN_SQ_NUMBER'], inplace=True)\n",
    "    #data.to_csv('data/historical_data_withflag.csv',index=False)\n",
    "    \n",
    "    #Imputation\n",
    "    CREDIT_SCORE = data['CREDIT_SCORE']\n",
    "    OIR = data['ORIGINAL_DTI_RATIO']\n",
    "    LTV = data['ORIGINAL_LTV']\n",
    "    CREDIT_clean = CREDIT_SCORE[CREDIT_SCORE != 9999]\n",
    "    OIR_clean = OIR[OIR != 999]\n",
    "    LTV_clean = LTV[LTV != 999]\n",
    "    data['CREDIT_SCORE'] = data['CREDIT_SCORE'].apply(lambda x : CREDIT_clean.mean() if x == 9999 else x)\n",
    "    data['ORIGINAL_DTI_RATIO'] = data['ORIGINAL_DTI_RATIO'].apply(lambda x : OIR_clean.mean() if x == 999 else x)\n",
    "    data['ORIGINAL_LTV'] = data['ORIGINAL_LTV'].apply(lambda x : LTV_clean.mean() if x == 999 else x)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Timer stop\n",
    "    time_end=time.time()\n",
    "    print('Finished loading, time cost:',time_end-time_start,'s')\n",
    "    return data\n",
    "    \n",
    "\n",
    "def train(data, fig, ax):\n",
    "    #Get dummy value\n",
    "    output_array = np.asarray(data['default_flag'].astype(int))\n",
    "    input_array = np.c_[\n",
    "        data[['CREDIT_SCORE',#0\n",
    "              'ORIGINAL_DTI_RATIO',#1\n",
    "              'ORIGINAL_UPB',#2\n",
    "              'ORIGINAL_LTV',#3\n",
    "              'ORIGINAL_LOAN_TERM',#4\n",
    "              'ORIGINAL_INTEREST_RATE'#5\n",
    "             ]],\n",
    "        np.asarray(pd.get_dummies(data['FIRST_TIME_HOMEBUYER_FLAG'])),\n",
    "        np.asarray(pd.get_dummies(data['NUMBER_OF_UNITS'])),\n",
    "        np.asarray(pd.get_dummies(data['OCCUPANCY_STATUS'])),\n",
    "        np.asarray(pd.get_dummies(data['CHANNEL'])),\n",
    "        np.asarray(pd.get_dummies(data['PROPERTY_TYPE'])),\n",
    "        np.asarray(pd.get_dummies(data['LOAN_PURPOSE'])),\n",
    "        np.asarray(pd.get_dummies(data['NUMBER_OF_BORROWERS']))\n",
    "    ]\n",
    "    \n",
    "    #Normalise\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    input_array_N = min_max_scaler.fit_transform(input_array)\n",
    "    \n",
    "    X = input_array_N\n",
    "    y = output_array\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.3, \n",
    "        random_state=13\n",
    "    )\n",
    "    \n",
    "    classifier = LogisticRegression(\n",
    "        tol= 1e-5,\n",
    "        C=0.1,\n",
    "        solver='saga',\n",
    "        max_iter=1500\n",
    "    )\n",
    "    \n",
    "    classifier.fit(X_train,y_train)\n",
    "    \n",
    "    viz = plot_roc_curve(\n",
    "        classifier, \n",
    "        X_test, \n",
    "        y_test,\n",
    "        name='Test ROC'.format(0),\n",
    "        alpha=0.5, lw=1, ax=ax\n",
    "    )\n",
    "    \n",
    "    viz_train = plot_roc_curve(\n",
    "        classifier, \n",
    "        X_train, \n",
    "        y_train,\n",
    "        name='Train ROC'.format(1),\n",
    "        alpha=0.5, lw=1, ax=ax\n",
    "    ) \n",
    "    \n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "        label='Chance', alpha=.8)\n",
    "    \n",
    "    ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
    "       title=\"Receiver operating characteristic example\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    return classifier, X_test, y_test, X_train, y_train\n",
    "####################################################################################\n",
    "\n",
    "def train_cross_validation(data):\n",
    "    #Get dummy value\n",
    "    output_array = np.asarray(data['default_flag'].astype(int))\n",
    "    input_array = np.c_[\n",
    "        data[['CREDIT_SCORE',#0\n",
    "              'ORIGINAL_DTI_RATIO',#1\n",
    "              'ORIGINAL_UPB',#2\n",
    "              'ORIGINAL_LTV',#3\n",
    "              'ORIGINAL_LOAN_TERM',#4\n",
    "              'ORIGINAL_INTEREST_RATE'#5\n",
    "             ]],\n",
    "        np.asarray(pd.get_dummies(data['FIRST_TIME_HOMEBUYER_FLAG'])),\n",
    "        np.asarray(pd.get_dummies(data['NUMBER_OF_UNITS'])),\n",
    "        np.asarray(pd.get_dummies(data['OCCUPANCY_STATUS'])),\n",
    "        np.asarray(pd.get_dummies(data['CHANNEL'])),\n",
    "        np.asarray(pd.get_dummies(data['PROPERTY_TYPE'])),\n",
    "        np.asarray(pd.get_dummies(data['LOAN_PURPOSE'])),\n",
    "        np.asarray(pd.get_dummies(data['NUMBER_OF_BORROWERS']))\n",
    "    ]\n",
    "    \n",
    "    #Normalise\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    input_array_N = min_max_scaler.fit_transform(input_array)\n",
    "    \n",
    "    X = input_array_N\n",
    "    y = output_array\n",
    "    \n",
    "    #devide Flods for cv\n",
    "    cv = StratifiedKFold(n_splits=6)\n",
    "    #define classifier\n",
    "    classifier = LogisticRegression(\n",
    "        solver='saga',\n",
    "        max_iter=1500\n",
    "    )\n",
    "\n",
    "    #tpr lists and auc value list\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    \n",
    "    #For ploting, prepare 500 points from 0-1\n",
    "    mean_fpr = np.linspace(0, 1, 500)\n",
    "      \n",
    "    #Loop training for every fold\n",
    "    for i, (train, test) in enumerate(cv.split(X, y)):\n",
    "        classifier.fit(X[train], y[train])\n",
    "        # put the curve in ax through 'ax = ax'\n",
    "        viz = plot_roc_curve(classifier, X[test], y[test],\n",
    "                             name='ROC fold {}'.format(i),\n",
    "                             alpha=0.3, lw=1, ax=ax)\n",
    "\n",
    "        #Plot every point (500) form 0-1, similiar to bin\n",
    "        interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        #Buff the result \n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(viz.roc_auc)\n",
    "\n",
    "    #Plot chance\n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "            label='Chance', alpha=.8)\n",
    "\n",
    "    #mean value for each colomn\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    \n",
    "    std_auc = np.std(aucs)\n",
    "    #Plot mean\n",
    "    ax.plot(mean_fpr, mean_tpr, color='b',\n",
    "            label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "            lw=2, alpha=.8)\n",
    "\n",
    "    #Plot standard tpr (Doesn't know the point for this step yet)\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                    label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "    \n",
    "    #Configure the diagram \n",
    "    ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
    "           title=\"Receiver operating characteristic example\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/2008/data\\historical_data1_Q12008.txt\n",
      "data/2008/data\\historical_data1_Q22008.txt\n",
      "data/2008/data\\historical_data1_Q32008.txt\n",
      "data/2008/data\\historical_data1_Q42008.txt\n",
      "data/2008/data_time\\historical_data1_time_Q12008.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda\\envs\\FYP\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3337: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/2008/data_time\\historical_data1_time_Q22008.txt\n",
      "data/2008/data_time\\historical_data1_time_Q32008.txt\n",
      "data/2008/data_time\\historical_data1_time_Q42008.txt\n",
      "Finished loading, time cost: 402.94464683532715 s\n",
      "data/2008/data\\historical_data1_Q12008.txt\n",
      "data/2008/data\\historical_data1_Q22008.txt\n",
      "data/2008/data\\historical_data1_Q32008.txt\n",
      "data/2008/data\\historical_data1_Q42008.txt\n",
      "data/2008/data_time\\historical_data1_time_Q12008.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda\\envs\\FYP\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3337: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/2008/data_time\\historical_data1_time_Q22008.txt\n",
      "data/2008/data_time\\historical_data1_time_Q32008.txt\n",
      "data/2008/data_time\\historical_data1_time_Q42008.txt\n",
      "Finished loading, time cost: 402.4353997707367 s\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'assert_frame_equal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6951891343c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdata1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_path_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdata2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data_divide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_path_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0massert_frame_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'assert_frame_equal' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    data_path = 'data/2005/data'\n",
    "    data_path_time = 'data/2005/data_time'\n",
    "    data = load_data(data_path, data_path_time)\n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    model, X_test, y_test, X_train, y_train= train(data, fig, ax)\n",
    "    fig.savefig('./figures/AUC_2005_log.jpg') \n",
    "    dump(model, './models/2004_logistic.joblib')\n",
    "    np.savetxt(\"./datasets/test/features/2005_log.csv\", X_test, delimiter=\",\")\n",
    "    np.savetxt(\"./datasets/test/target/2005_log.csv\", y_test, delimiter=\",\")\n",
    "    np.savetxt(\"./datasets/train/features/2005_log.csv\", X_train, delimiter=\",\")\n",
    "    np.savetxt(\"./datasets/train/target/2005_log.csv\", y_train, delimiter=\",\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
