{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import dump, load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def load_data(data_path, data_path_time):\n",
    "    time_start=time.time()\n",
    "    \n",
    "    #Load data\n",
    "    data_list = []\n",
    "    for fname in sorted(os.listdir(data_path)):\n",
    "        subject_data_path = os.path.join(data_path, fname)\n",
    "        print(subject_data_path)\n",
    "        if not os.path.isfile(subject_data_path): continue\n",
    "        data_list.append(\n",
    "            pd.read_csv(\n",
    "                        subject_data_path,\n",
    "                        sep='|', \n",
    "                        header=None,\n",
    "                        names = [\n",
    "                                'CREDIT_SCORE',\n",
    "                                'FIRST_PAYMENT_DATE',\n",
    "                                'FIRST_TIME_HOMEBUYER_FLAG',\n",
    "                                '4','5','6',\n",
    "                                'NUMBER_OF_UNITS',\n",
    "                                'OCCUPANCY_STATUS',\n",
    "                                '9',\n",
    "                                'ORIGINAL_DTI_RATIO',\n",
    "                                'ORIGINAL_UPB',\n",
    "                                'ORIGINAL_LTV',\n",
    "                                'ORIGINAL_INTEREST_RATE',\n",
    "                                'CHANNEL',\n",
    "                                '15',\n",
    "                                'PRODUCT_TYPE',\n",
    "                                'PROPERTY_STATE',\n",
    "                                'PROPERTY_TYPE',\n",
    "                                '19',\n",
    "                                'LOAN_SQ_NUMBER',\n",
    "                                'LOAN_PURPOSE',\n",
    "                                'ORIGINAL_LOAN_TERM',\n",
    "                                'NUMBER_OF_BORROWERS',\n",
    "                                '24','25','26','27'#data from every year may have different column number\n",
    "                            #2004-2007: 27 2008: 26 2009: 27\n",
    "                        ],\n",
    "                        usecols=[\n",
    "                            'CREDIT_SCORE',\n",
    "                            'FIRST_TIME_HOMEBUYER_FLAG',\n",
    "                            'NUMBER_OF_UNITS',\n",
    "                            'OCCUPANCY_STATUS',\n",
    "                            'ORIGINAL_DTI_RATIO',\n",
    "                            'ORIGINAL_UPB',\n",
    "                            'ORIGINAL_LTV',\n",
    "                            'ORIGINAL_INTEREST_RATE',\n",
    "                            'CHANNEL',\n",
    "                            'PROPERTY_TYPE',\n",
    "                            'LOAN_SQ_NUMBER',\n",
    "                            'LOAN_PURPOSE',\n",
    "                            'ORIGINAL_LOAN_TERM',\n",
    "                            'NUMBER_OF_BORROWERS'\n",
    "                        ],\n",
    "                        dtype={'CREDIT_SCORE':np.float_, \n",
    "                               'FIRST_TIME_HOMEBUYER_FLAG':np.str, \n",
    "                               'NUMBER_OF_UNITS':np.int_, \n",
    "                               'OCCUPANCY_STATUS':np.str,\n",
    "                               'ORIGINAL_DTI_RATIO':np.float_,\n",
    "                               'ORIGINAL_UPB':np.float_,\n",
    "                               'ORIGINAL_LTV':np.float_,\n",
    "                               'ORIGINAL_INTEREST_RATE':np.float_,\n",
    "                               'CHANNEL':np.str,\n",
    "                               'PROPERTY_TYPE':np.str,\n",
    "                               'LOAN_SQ_NUMBER':np.str,\n",
    "                               'LOAN_PURPOSE':np.str,\n",
    "                               'ORIGINAL_LOAN_TERM':np.int_,\n",
    "                               'NUMBER_OF_BORROWERS':np.int_},\n",
    "                        low_memory=False\n",
    "                        )\n",
    "        )\n",
    "    data = pd.concat(data_list)\n",
    "    \n",
    "    #Load data with time\n",
    "    data_p_list=[]\n",
    "    for fname in sorted(os.listdir(data_path_time)):\n",
    "        subject_data_path = os.path.join(data_path_time, fname)\n",
    "        print(subject_data_path)\n",
    "        if not os.path.isfile(subject_data_path): continue\n",
    "        data_p_list.append(\n",
    "            pd.read_csv(subject_data_path,\n",
    "                             sep='|',\n",
    "                             header=None,\n",
    "                             usecols=[0,3,4],\n",
    "                             dtype={'0':np.str, '3':np.str, '4':np.int_}\n",
    "                            )\n",
    "        )\n",
    "    #data_p = pd.concat(data_p_list)\n",
    "    \n",
    "    #Calculate default\n",
    "    default_list=[]\n",
    "    for data_p in data_p_list:\n",
    "        data_p[3] = data_p[3].astype(str)\n",
    "        clean_index = data_p.iloc[:,1].str.isdigit()\n",
    "        data_p_cleaned = data_p[clean_index].copy()\n",
    "        data_p_cleaned[3] = data_p_cleaned[3].astype(int)\n",
    "        data_less_than_48 = data_p_cleaned[data_p_cleaned[4] < 48]\n",
    "        default_list.append(data_less_than_48[data_less_than_48[3] > 2])\n",
    "    \n",
    "    data_default = pd.concat(default_list)\n",
    "    \n",
    "    default_index = data['LOAN_SQ_NUMBER'].isin(data_default[0].tolist())\n",
    "    \n",
    "    \n",
    "    \n",
    "    data['default_flag']=default_index\n",
    "    \n",
    "    \n",
    "    data.drop(columns=['LOAN_SQ_NUMBER'], inplace=True)\n",
    "    #data.to_csv('data/historical_data_withflag.csv',index=False)\n",
    "    \n",
    "    #Imputation\n",
    "    CREDIT_SCORE = data['CREDIT_SCORE']\n",
    "    OIR = data['ORIGINAL_DTI_RATIO']\n",
    "    LTV = data['ORIGINAL_LTV']\n",
    "    CREDIT_clean = CREDIT_SCORE[CREDIT_SCORE != 9999]\n",
    "    OIR_clean = OIR[OIR != 999]\n",
    "    LTV_clean = LTV[LTV != 999]\n",
    "    data['CREDIT_SCORE'] = data['CREDIT_SCORE'].apply(lambda x : CREDIT_clean.mean() if x == 9999 else x)\n",
    "    data['ORIGINAL_DTI_RATIO'] = data['ORIGINAL_DTI_RATIO'].apply(lambda x : OIR_clean.mean() if x == 999 else x)\n",
    "    data['ORIGINAL_LTV'] = data['ORIGINAL_LTV'].apply(lambda x : LTV_clean.mean() if x == 999 else x)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Timer stop\n",
    "    time_end=time.time()\n",
    "    print('Finished loading, time cost:',time_end-time_start,'s')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def train_log(data, fig, ax, year):\n",
    "   \n",
    "    time_start=time.time()\n",
    "    #Get dummy value\n",
    "    \n",
    "    data['FIRST_TIME_HOMEBUYER_FLAG'] = data['FIRST_TIME_HOMEBUYER_FLAG'].apply(lambda x : np.NaN if x == '9' else x)\n",
    "    data['NUMBER_OF_UNITS'] = data['NUMBER_OF_UNITS'].apply(lambda x : np.NaN if x == 99 else x)\n",
    "    data['CHANNEL'] = data['CHANNEL'].apply(lambda x : np.NaN if x == 'T' else x)\n",
    "    data['PROPERTY_TYPE'] = data['PROPERTY_TYPE'].apply(lambda x : np.NaN if x == '99' else x)\n",
    "    data['NUMBER_OF_BORROWERS'] = data['NUMBER_OF_BORROWERS'].apply(lambda x : np.NaN if x == 99 else x)\n",
    "    \n",
    "    \n",
    "    output_array = np.asarray(data['default_flag'].astype(int))\n",
    "    input_array = np.c_[\n",
    "        data[['CREDIT_SCORE',#0\n",
    "              'ORIGINAL_DTI_RATIO',#1\n",
    "              'ORIGINAL_UPB',#2\n",
    "              'ORIGINAL_LTV',#3\n",
    "              'ORIGINAL_LOAN_TERM',#4\n",
    "              'ORIGINAL_INTEREST_RATE'#5\n",
    "             ]],\n",
    "        np.asarray(pd.get_dummies(data['FIRST_TIME_HOMEBUYER_FLAG'])), # N,Y,9 str remove 9\n",
    "        np.asarray(pd.get_dummies(data['NUMBER_OF_UNITS'])), # 1 2 3 4 99 int remove 99\n",
    "        np.asarray(pd.get_dummies(data['OCCUPANCY_STATUS'])), # P S I str\n",
    "        np.asarray(pd.get_dummies(data['CHANNEL'])), # T R C B str remove T\n",
    "        np.asarray(pd.get_dummies(data['PROPERTY_TYPE'])), # SF PU CO MH CP 99 str remove 99\n",
    "        np.asarray(pd.get_dummies(data['LOAN_PURPOSE'])), # P N C str\n",
    "        np.asarray(pd.get_dummies(data['NUMBER_OF_BORROWERS'])) # 2 1 99 int remove 99\n",
    "    ]\n",
    "    \n",
    "    #Normalise\n",
    "    #min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    #input_array_N = min_max_scaler.fit_transform(input_array)\n",
    "    \n",
    "#     train_path_X = 'datasets/train/features/'\n",
    "#     train_path_y = 'datasets/train/target/'\n",
    "#     test_path_X = 'datasets/test/features/'\n",
    "#     test_path_y = 'datasets/test/target/'\n",
    "    \n",
    "    \n",
    "    X = input_array\n",
    "    y = output_array\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.3, \n",
    "        random_state=13\n",
    "    )\n",
    "    \n",
    "    classifier = LogisticRegression(\n",
    "        tol= 1e-5,\n",
    "        #C=0.1,\n",
    "        #class_weight = 'balanced',\n",
    "        #class_weight = {0:0.01, 1:0.99},\n",
    "        #solver='sag',\n",
    "        max_iter=1500,\n",
    "        n_jobs = -1\n",
    "    )\n",
    "    \n",
    "    classifier.fit(X_train,y_train)\n",
    "    \n",
    "    viz = plot_roc_curve(\n",
    "        classifier, \n",
    "        X_test, \n",
    "        y_test,\n",
    "        name='Test ROC'.format(0),\n",
    "        alpha=0.5, lw=1, ax=ax\n",
    "    )\n",
    "    \n",
    "    viz_train = plot_roc_curve(\n",
    "        classifier, \n",
    "        X_train, \n",
    "        y_train,\n",
    "        name='Train ROC'.format(1),\n",
    "        alpha=0.5, lw=1, ax=ax\n",
    "    ) \n",
    "    \n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "        label='Chance', alpha=.8)\n",
    "    \n",
    "    ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
    "       title=\"Receiver operating characteristic example\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    time_end=time.time()\n",
    "    print('Training done, time cost:',time_end-time_start,'s')\n",
    "    \n",
    "    print(classifier.predict_proba(X_test)[:, 1])\n",
    "    return classifier, X_test, y_test, X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def train_NN(data, fig, ax):\n",
    "   \n",
    "    time_start=time.time()\n",
    "    #Get dummy value\n",
    "    \n",
    "    data['FIRST_TIME_HOMEBUYER_FLAG'] = data['FIRST_TIME_HOMEBUYER_FLAG'].apply(lambda x : np.NaN if x == '9' else x)\n",
    "    data['NUMBER_OF_UNITS'] = data['NUMBER_OF_UNITS'].apply(lambda x : np.NaN if x == 99 else x)\n",
    "    data['CHANNEL'] = data['CHANNEL'].apply(lambda x : np.NaN if x == 'T' else x)\n",
    "    data['PROPERTY_TYPE'] = data['PROPERTY_TYPE'].apply(lambda x : np.NaN if x == '99' else x)\n",
    "    data['NUMBER_OF_BORROWERS'] = data['NUMBER_OF_BORROWERS'].apply(lambda x : np.NaN if x == 99 else x)\n",
    "    \n",
    "    \n",
    "    output_array = np.asarray(data['default_flag'].astype(int))\n",
    "    input_array = np.c_[\n",
    "        data[['CREDIT_SCORE',#0\n",
    "              'ORIGINAL_DTI_RATIO',#1\n",
    "              'ORIGINAL_UPB',#2\n",
    "              'ORIGINAL_LTV',#3\n",
    "              'ORIGINAL_LOAN_TERM',#4\n",
    "              'ORIGINAL_INTEREST_RATE'#5\n",
    "             ]],\n",
    "        np.asarray(pd.get_dummies(data['FIRST_TIME_HOMEBUYER_FLAG'])), # N,Y,9 str remove 9\n",
    "        np.asarray(pd.get_dummies(data['NUMBER_OF_UNITS'])), # 1 2 3 4 99 int remove 99\n",
    "        np.asarray(pd.get_dummies(data['OCCUPANCY_STATUS'])), # P S I str\n",
    "        np.asarray(pd.get_dummies(data['CHANNEL'])), # T R C B str remove T\n",
    "        np.asarray(pd.get_dummies(data['PROPERTY_TYPE'])), # SF PU CO MH CP 99 str remove 99\n",
    "        np.asarray(pd.get_dummies(data['LOAN_PURPOSE'])), # P N C str\n",
    "        np.asarray(pd.get_dummies(data['NUMBER_OF_BORROWERS'])) # 2 1 99 int remove 99\n",
    "    ]\n",
    "    \n",
    "    #Normalise\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    input_array_N = min_max_scaler.fit_transform(input_array)\n",
    "    \n",
    "    X = input_array_N\n",
    "    y = output_array\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.3, \n",
    "        random_state=13\n",
    "    )\n",
    "    \n",
    "    classifier = LogisticRegression(\n",
    "        tol= 1e-5,\n",
    "        C=0.1,\n",
    "        class_weight = 'balanced',\n",
    "        #solver='sag',\n",
    "        max_iter=1500\n",
    "    )\n",
    "    \n",
    "    classifier.fit(X_train,y_train)\n",
    "    \n",
    "    viz = plot_roc_curve(\n",
    "        classifier, \n",
    "        X_test, \n",
    "        y_test,\n",
    "        name='Test ROC'.format(0),\n",
    "        alpha=0.5, lw=1, ax=ax\n",
    "    )\n",
    "    \n",
    "    viz_train = plot_roc_curve(\n",
    "        classifier, \n",
    "        X_train, \n",
    "        y_train,\n",
    "        name='Train ROC'.format(1),\n",
    "        alpha=0.5, lw=1, ax=ax\n",
    "    ) \n",
    "    \n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "        label='Chance', alpha=.8)\n",
    "    \n",
    "    ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
    "       title=\"Receiver operating characteristic example\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    time_end=time.time()\n",
    "    print('Training done, time cost:',time_end-time_start,'s')\n",
    "    return classifier, X_test, y_test, X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def train_log_cross_validation(data):\n",
    "    #Get dummy value\n",
    "    output_array = np.asarray(data['default_flag'].astype(int))\n",
    "    input_array = np.c_[\n",
    "        data[['CREDIT_SCORE',#0\n",
    "              'ORIGINAL_DTI_RATIO',#1\n",
    "              'ORIGINAL_UPB',#2\n",
    "              'ORIGINAL_LTV',#3\n",
    "              'ORIGINAL_LOAN_TERM',#4\n",
    "              'ORIGINAL_INTEREST_RATE'#5\n",
    "             ]],\n",
    "        np.asarray(pd.get_dummies(data['FIRST_TIME_HOMEBUYER_FLAG'])),\n",
    "        np.asarray(pd.get_dummies(data['NUMBER_OF_UNITS'])),\n",
    "        np.asarray(pd.get_dummies(data['OCCUPANCY_STATUS'])),\n",
    "        np.asarray(pd.get_dummies(data['CHANNEL'])),\n",
    "        np.asarray(pd.get_dummies(data['PROPERTY_TYPE'])),\n",
    "        np.asarray(pd.get_dummies(data['LOAN_PURPOSE'])),\n",
    "        np.asarray(pd.get_dummies(data['NUMBER_OF_BORROWERS']))\n",
    "    ]\n",
    "    \n",
    "    #Normalise\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    input_array_N = min_max_scaler.fit_transform(input_array)\n",
    "    \n",
    "    X = input_array_N\n",
    "    y = output_array\n",
    "    \n",
    "    #devide Flods for cv\n",
    "    cv = StratifiedKFold(n_splits=6)\n",
    "    #define classifier\n",
    "    classifier = LogisticRegression(\n",
    "        solver='saga',\n",
    "        max_iter=1500\n",
    "    )\n",
    "\n",
    "    #tpr lists and auc value list\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    \n",
    "    #For ploting, prepare 500 points from 0-1\n",
    "    mean_fpr = np.linspace(0, 1, 500)\n",
    "      \n",
    "    #Loop training for every fold\n",
    "    for i, (train, test) in enumerate(cv.split(X, y)):\n",
    "        classifier.fit(X[train], y[train])\n",
    "        # put the curve in ax through 'ax = ax'\n",
    "        viz = plot_roc_curve(classifier, X[test], y[test],\n",
    "                             name='ROC fold {}'.format(i),\n",
    "                             alpha=0.3, lw=1, ax=ax)\n",
    "\n",
    "        #Plot every point (500) form 0-1, similiar to bin\n",
    "        interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        #Buff the result \n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(viz.roc_auc)\n",
    "\n",
    "    #Plot chance\n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "            label='Chance', alpha=.8)\n",
    "\n",
    "    #mean value for each colomn\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    \n",
    "    std_auc = np.std(aucs)\n",
    "    #Plot mean\n",
    "    ax.plot(mean_fpr, mean_tpr, color='b',\n",
    "            label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "            lw=2, alpha=.8)\n",
    "\n",
    "    #Plot standard tpr (Doesn't know the point for this step yet)\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                    label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "    \n",
    "    #Configure the diagram \n",
    "    ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
    "           title=\"Receiver operating characteristic example\")\n",
    "    ax.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "#     year_list = ['2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014']\n",
    "    year_list = ['2004', '2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015','2016','2017','2018']\n",
    "\n",
    "#     for year_ in year_list:\n",
    "#         data_path = 'data/{year}/data'.format(year=year_)\n",
    "#         data_path_time = 'data/{year}/data_time'.format(year=year_)\n",
    "#         data = load_data(data_path, data_path_time)\n",
    "#         data.to_csv('data_flag/{}_flag.csv'.format(year_))\n",
    "        \n",
    "    for year_ in year_list:\n",
    "        print(\"Loading data...\")\n",
    "        data_path = 'data_flag/{year}_flag.csv'.format(year=year_)  \n",
    "        cols = pd.read_csv(data_path).columns\n",
    "        data = pd.read_csv(data_path, usecols = cols[1:]) \n",
    "        y = np.asarray(data['default_flag'].astype(int))\n",
    "        fig, ax = plt.subplots(figsize=(15, 8))         \n",
    "        print(\"Training start...\")\n",
    "        model, X_test, y_test, X_train, y_train= train_log(data, fig, ax, year_)\n",
    "        plt.show()\n",
    "        fig.savefig('./log_AUC_without_norm/AUC_{year}_log.jpg'.format(year=year_)) \n",
    "        dump(model, './log_without_norm_models/{year}_logistic.joblib'.format(year=year_))\n",
    "        np.savetxt(\"./without_norm_datasets/test/features/{year}_log.csv\".format(year=year_), X_test, delimiter=\",\")\n",
    "        np.savetxt(\"./without_norm_datasets/test/target/{year}_log.csv\".format(year=year_), y_test, delimiter=\",\")\n",
    "        np.savetxt(\"./without_norm_datasets/train/features/{year}_log.csv\".format(year=year_), X_train, delimiter=\",\")\n",
    "        np.savetxt(\"./without_norm_datasets/train/target/{year}_log.csv\".format(year=year_), y_train, delimiter=\",\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     year_list = ['2004', '2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015','2016','2017','2018']\n",
    "#     data_ = []\n",
    "#     default = []\n",
    "#     total = []\n",
    "#     for year_ in year_list:\n",
    "#         print(\"Loading data...\")\n",
    "#         data_path = 'data_flag/{year}_flag.csv'.format(year=year_)  \n",
    "#         cols = pd.read_csv(data_path).columns\n",
    "#         data = pd.read_csv(data_path, usecols = cols[1:]) \n",
    "#         y = np.asarray(data['default_flag'].astype(int))\n",
    "#         u_ele, ct_ele = np.unique(y, return_counts=True)\n",
    "#         default.append(ct_ele[1])\n",
    "#         total.append(np.size(y))\n",
    "#     data_.append(default)\n",
    "#     data_.append(total)\n",
    "#     columns = ['%d' % x for x in np.arange(2004,2019)]\n",
    "#     rows = ['default','number of accounts'] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     fig, ax = plt.subplots(figsize=(30, 20))\n",
    "#     values = np.arange(0, 2500, 500)\n",
    "#     value_increment = 10000\n",
    "#     colors = plt.cm.BuPu(np.linspace(0, 0.5, len(rows)))\n",
    "#     n_rows = len(data_)\n",
    "\n",
    "#     index = np.arange(len(columns)) + 0.6\n",
    "#     bar_width = 0.4\n",
    "\n",
    "#     # Initialize the vertical-offset for the stacked bar chart.\n",
    "#     y_offset = np.zeros(len(columns))\n",
    "\n",
    "#     # Plot bars and create text labels for the table\n",
    "#     #cell_text = []\n",
    "#     for row in range(n_rows):\n",
    "#         bar = plt.bar(index, data_[row], bar_width, bottom=y_offset, color=colors[row])\n",
    "#         y_offset = y_offset + data_[row]\n",
    "#         cell_text.append(['%d' % x for x in y_offset])\n",
    "#     # Reverse colors and text labels to display the last value at the top.\n",
    "#     colors = colors[::1]\n",
    "#     #cell_text.reverse()\n",
    "\n",
    "#     # Add a table at the bottom of the axes\n",
    "#     the_table = plt.table(cellText=data_,\n",
    "#                           rowLabels=rows,\n",
    "#                           rowColours=colors,\n",
    "#                           colLabels=columns,\n",
    "#                           loc='bottom')\n",
    "#     the_table.set_fontsize(25)\n",
    "#     the_table.scale(1.0, 2.0)  # may help\n",
    "\n",
    "#     # Adjust layout to make room for the table:\n",
    "#     #plt.subplots_adjust(left=0.2, bottom=0.2)\n",
    "#     values = np.arange(0, 2000000, 500000)\n",
    "#     value_increment = 1000\n",
    "#     plt.ylabel(\"Person\",fontsize = 20)\n",
    "#     plt.yticks(values, ['%d' % val for val in values], fontsize = 20)\n",
    "#     plt.xticks([])\n",
    "#     plt.title('Default counts by years',fontsize = 20)\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig.savefig('./Defaults.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
