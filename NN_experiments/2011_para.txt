# Tuning hyper-parameters for AUC
Fitting 5 folds for each of 108 candidates, totalling 540 fits
[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.
[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:  2.6min
[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed: 16.4min
[Parallel(n_jobs=7)]: Done 436 tasks      | elapsed: 43.0min
[Parallel(n_jobs=7)]: Done 540 out of 540 | elapsed: 57.5min finished
Best parameters set found on development set:

{'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (15,), 'learning_rate_init': 0.001}

Grid scores on development set:

0.721 (+/-0.012) for {'activation': 'logistic', 'alpha': 0.1, 'hidden_layer_sizes': (5,), 'learning_rate_init': 0.01}
0.728 (+/-0.009) for {'activation': 'logistic', 'alpha': 0.1, 'hidden_layer_sizes': (5,), 'learning_rate_init': 0.001}
0.731 (+/-0.008) for {'activation': 'logistic', 'alpha': 0.1, 'hidden_layer_sizes': (5,), 'learning_rate_init': 0.0001}
0.723 (+/-0.025) for {'activation': 'logistic', 'alpha': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}
0.729 (+/-0.009) for {'activation': 'logistic', 'alpha': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}
0.731 (+/-0.008) for {'activation': 'logistic', 'alpha': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.0001}
0.722 (+/-0.012) for {'activation': 'logistic', 'alpha': 0.1, 'hidden_layer_sizes': (15,), 'learning_rate_init': 0.01}
0.728 (+/-0.008) for {'activation': 'logistic', 'alpha': 0.1, 'hidden_layer_sizes': (15,), 'learning_rate_init': 0.001}
0.732 (+/-0.008) for {'activation': 'logistic', 'alpha': 0.1, 'hidden_layer_sizes': (15,), 'learning_rate_init': 0.0001}
0.481 (+/-0.248) for {'activation': 'logistic', 'alpha': 0.1, 'hidden_layer_sizes': (5, 5), 'learning_rate_init': 0.01}
0.591 (+/-0.171) for {'activation': 'logistic', 'alpha': 0.1, 'hidden_layer_sizes': (5, 5), 'learning_rate_init': 0.001}
0.719 (+/-0.008) for {'activation': 'logistic', 'alpha': 0.1, 'hidden_layer_sizes': (5, 5), 'learning_rate_init': 0.0001}
0.838 (+/-0.011) for {'activation': 'logistic', 'alpha': 0.01, 'hidden_layer_sizes': (5,), 'learning_rate_init': 0.01}
0.837 (+/-0.009) for {'activation': 'logistic', 'alpha': 0.01, 'hidden_layer_sizes': (5,), 'learning_rate_init': 0.001}
0.752 (+/-0.011) for {'activation': 'logistic', 'alpha': 0.01, 'hidden_layer_sizes': (5,), 'learning_rate_init': 0.0001}
0.841 (+/-0.008) for {'activation': 'logistic', 'alpha': 0.01, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}
0.836 (+/-0.011) for {'activation': 'logistic', 'alpha': 0.01, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}
0.758 (+/-0.010) for {'activation': 'logistic', 'alpha': 0.01, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.0001}
0.837 (+/-0.013) for {'activation': 'logistic', 'alpha': 0.01, 'hidden_layer_sizes': (15,), 'learning_rate_init': 0.01}
0.835 (+/-0.008) for {'activation': 'logistic', 'alpha': 0.01, 'hidden_layer_sizes': (15,), 'learning_rate_init': 0.001}
0.762 (+/-0.007) for {'activation': 'logistic', 'alpha': 0.01, 'hidden_layer_sizes': (15,), 'learning_rate_init': 0.0001}
0.843 (+/-0.014) for {'activation': 'logistic', 'alpha': 0.01, 'hidden_layer_sizes': (5, 5), 'learning_rate_init': 0.01}
0.844 (+/-0.011) for {'activation': 'logistic', 'alpha': 0.01, 'hidden_layer_sizes': (5, 5), 'learning_rate_init': 0.001}
0.734 (+/-0.007) for {'activation': 'logistic', 'alpha': 0.01, 'hidden_layer_sizes': (5, 5), 'learning_rate_init': 0.0001}
0.851 (+/-0.012) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': (5,), 'learning_rate_init': 0.01}
0.850 (+/-0.012) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': (5,), 'learning_rate_init': 0.001}
0.749 (+/-0.014) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': (5,), 'learning_rate_init': 0.0001}
0.851 (+/-0.012) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}
0.851 (+/-0.012) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}
0.754 (+/-0.005) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.0001}
0.849 (+/-0.013) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': (15,), 'learning_rate_init': 0.01}
0.852 (+/-0.011) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': (15,), 'learning_rate_init': 0.001}
0.763 (+/-0.006) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': (15,), 'learning_rate_init': 0.0001}
0.851 (+/-0.013) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': (5, 5), 'learning_rate_init': 0.01}
0.851 (+/-0.012) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': (5, 5), 'learning_rate_init': 0.001}
0.741 (+/-0.008) for {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': (5, 5), 'learning_rate_init': 0.0001}
0.774 (+/-0.010) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (5,), 'learning_rate_init': 0.01}
0.800 (+/-0.013) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (5,), 'learning_rate_init': 0.001}
0.769 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (5,), 'learning_rate_init': 0.0001}
0.763 (+/-0.014) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}
0.798 (+/-0.004) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}
0.786 (+/-0.003) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.0001}
0.772 (+/-0.012) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (15,), 'learning_rate_init': 0.01}
0.797 (+/-0.010) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (15,), 'learning_rate_init': 0.001}
0.797 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (15,), 'learning_rate_init': 0.0001}
0.809 (+/-0.019) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (5, 5), 'learning_rate_init': 0.01}
0.835 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (5, 5), 'learning_rate_init': 0.001}
0.808 (+/-0.026) for {'activation': 'tanh', 'alpha': 0.1, 'hidden_layer_sizes': (5, 5), 'learning_rate_init': 0.0001}
0.849 (+/-0.012) for {'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (5,), 'learning_rate_init': 0.01}
0.852 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (5,), 'learning_rate_init': 0.001}
0.840 (+/-0.013) for {'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (5,), 'learning_rate_init': 0.0001}
0.848 (+/-0.015) for {'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}
0.852 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}
0.845 (+/-0.009) for {'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.0001}
0.850 (+/-0.012) for {'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (15,), 'learning_rate_init': 0.01}
0.851 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (15,), 'learning_rate_init': 0.001}
0.846 (+/-0.012) for {'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (15,), 'learning_rate_init': 0.0001}
0.848 (+/-0.010) for {'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (5, 5), 'learning_rate_init': 0.01}
0.852 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (5, 5), 'learning_rate_init': 0.001}
0.849 (+/-0.010) for {'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (5, 5), 'learning_rate_init': 0.0001}
0.851 (+/-0.013) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (5,), 'learning_rate_init': 0.01}
0.853 (+/-0.012) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (5,), 'learning_rate_init': 0.001}
0.842 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (5,), 'learning_rate_init': 0.0001}
0.851 (+/-0.010) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}
0.853 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}
0.843 (+/-0.013) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.0001}
0.852 (+/-0.010) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (15,), 'learning_rate_init': 0.01}
0.853 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (15,), 'learning_rate_init': 0.001}
0.846 (+/-0.008) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (15,), 'learning_rate_init': 0.0001}
0.852 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (5, 5), 'learning_rate_init': 0.01}
0.852 (+/-0.011) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (5, 5), 'learning_rate_init': 0.001}
0.845 (+/-0.017) for {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (5, 5), 'learning_rate_init': 0.0001}
0.780 (+/-0.009) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (5,), 'learning_rate_init': 0.01}
0.807 (+/-0.008) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (5,), 'learning_rate_init': 0.001}
0.768 (+/-0.016) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (5,), 'learning_rate_init': 0.0001}
0.773 (+/-0.013) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}
0.807 (+/-0.014) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}
0.791 (+/-0.014) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.0001}
0.783 (+/-0.010) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (15,), 'learning_rate_init': 0.01}
0.805 (+/-0.009) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (15,), 'learning_rate_init': 0.001}
0.800 (+/-0.008) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (15,), 'learning_rate_init': 0.0001}
0.807 (+/-0.004) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (5, 5), 'learning_rate_init': 0.01}
0.836 (+/-0.010) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (5, 5), 'learning_rate_init': 0.001}
0.788 (+/-0.049) for {'activation': 'relu', 'alpha': 0.1, 'hidden_layer_sizes': (5, 5), 'learning_rate_init': 0.0001}
0.849 (+/-0.011) for {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (5,), 'learning_rate_init': 0.01}
0.852 (+/-0.011) for {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (5,), 'learning_rate_init': 0.001}
0.827 (+/-0.017) for {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (5,), 'learning_rate_init': 0.0001}
0.848 (+/-0.014) for {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}
0.851 (+/-0.012) for {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}
0.840 (+/-0.011) for {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.0001}
0.848 (+/-0.013) for {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (15,), 'learning_rate_init': 0.01}
0.851 (+/-0.011) for {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (15,), 'learning_rate_init': 0.001}
0.841 (+/-0.010) for {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (15,), 'learning_rate_init': 0.0001}
0.848 (+/-0.009) for {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (5, 5), 'learning_rate_init': 0.01}
0.782 (+/-0.282) for {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (5, 5), 'learning_rate_init': 0.001}
0.840 (+/-0.012) for {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (5, 5), 'learning_rate_init': 0.0001}
0.851 (+/-0.013) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (5,), 'learning_rate_init': 0.01}
0.852 (+/-0.010) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (5,), 'learning_rate_init': 0.001}
0.816 (+/-0.068) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (5,), 'learning_rate_init': 0.0001}
0.851 (+/-0.015) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}
0.851 (+/-0.012) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}
0.842 (+/-0.014) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.0001}
0.850 (+/-0.010) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (15,), 'learning_rate_init': 0.01}
0.853 (+/-0.011) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (15,), 'learning_rate_init': 0.001}
0.844 (+/-0.012) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (15,), 'learning_rate_init': 0.0001}
0.851 (+/-0.011) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (5, 5), 'learning_rate_init': 0.01}
0.853 (+/-0.010) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (5, 5), 'learning_rate_init': 0.001}
0.843 (+/-0.013) for {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (5, 5), 'learning_rate_init': 0.0001}

Detailed classification report:

The model is trained on the full development set.
The scores are computed on the full evaluation set.

G:\Anaconda\envs\FYP\lib\site-packages\sklearn\metrics\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

           0       0.99      1.00      1.00    285212
           1       0.00      0.00      0.00      1545

    accuracy                           0.99    286757
   macro avg       0.50      0.50      0.50    286757
weighted avg       0.99      0.99      0.99    286757